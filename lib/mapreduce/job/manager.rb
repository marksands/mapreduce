module MapReduce
  class Job
    # Manages the book keeping of redis keys and redis usage
    # All interaction with redis should go through this class
    # 
    class Manager < QueueProcess
      include RedisSupport

      # Holds the current map reduce processes that are either running or which still have data lying around
      #
      redis_key :jobs, "map_reduce:jobs"

      # Holds the information (mapper, reducer, etc.) in json format for a map reduce job with pid PID
      #
      redis_key :pid, "map_reduce_job:PID"

      # All the keys that the map produced
      #
      redis_key :keys, "map_reduce_job:PID:keys"

      # The hashed key to actual string value of key
      #
      redis_key :hash_to_key, "map_reduce_job:PID:keys:HASHED_KEY" # to ACTUAL KEY
      
      # The list of values for a given key generated by our map function.
      # When a reduce is run it takes elements from this key and pushes them to :reduce
      #
      # key - list of values
      #
      redis_key :map, "map_reduce_job:PID:map_key:HASHED_KEY"
      redis_key :reduce, "map_reduce_job:PID:map_key:HASHED_KEY:reduce"
      
      # Temporary redis space for reduce functions to use
      #
      redis_key :temp, "map_reduce_job:PID:temp_reduce_key:HASHED_KEY:UNIQUE_REDUCE_HOSTNAME:UNIQUE_REDUCE_PROCESS_ID"

      # If we want to hold on to our final data we have a key to put that data in
      # In normal map reduce we would just be outputting files
      #
      redis_key :result, "map_reduce_job:PID:result"
      redis_key :result_custom_key, "map_reduce:result:KEYNAME"

      def self.all_info(pid)
        redis.keys(Keys.pid(pid) + "*")
      end
      
      def self.authorize(pid, spec)
        redis.sadd(Keys.jobs, pid)
        redis.set(Keys.pid(pid), spec.to_json)
      end

      def self.get_job(pid)
        redis.get(Keys.pid(pid))
      end

      # Keys that the map operation produced
      #
      # pid  - The process id
      #
      # Examples
      #   Job::Manager::get_keys(pid)
      #   # =>
      #
      # Returns the Keys.
      def self.get_keys(pid)
        job = Job.open(pid)
        return unless job
        
        if( not job.ordered )
          redis.smembers( Keys.keys(pid) )
        else
          redis.zrange( Keys.keys(pid), 0, -1 )
        end
      end

      def self.num_values(pid, key)
        hashed_key = Support.hash(key)
        redis.llen( Keys.map(pid, hashed_key) )
      end

      def self.get_values(pid, key)
        hashed_key = Support.hash(key)
        redis.lrange( Keys.map(pid, hashed_key), 0, -1 )
      end

      
      def self.get_reduced_values(pid, key)
        hashed_key = Support.hash(key)
        redis.lrange( Keys.reduce(pid, hashed_key), 0, -1 )
      end

      # Emissions, when we get map/reduce results back we emit these 
      # to be stored in our file system (redis)
      #
      # pid_or_job - The process or job id
      # key_value  - The key, value
      #
      # Examples
      #   Job::Manager::emit_intermediate(pid, [key, value])
      #   # =>
      #
      # Returns the true on success.
      def self.emit_intermediate(pid_or_job, key_value)
        job = Job.open(pid_or_job)
        return unless job

        if( not job.ordered )
          key, value = key_value
          redis.sadd( Keys.keys(job.pid), key )
          hashed_key = Support.hash(key)
          redis.rpush( Keys.map(job.pid, hashed_key), value )
        else
          # if there's an order for the job then we should use a zset above
          # ordered job's map emits [rank, key, value]
          #
          rank, key, value = key_value
          redis.zadd( Keys.keys(job.pid), rank, key )
          hashed_key = Support.hash(key)
          redis.rpush( Keys.map(job.pid, hashed_key), value )
        end
        raise "Key Collision: key:#{key}, #{key.class} => hashed key:#{hashed_key}" if key_collision?(job.pid, hashed_key, key)
        true
      end

      def self.emit(pid, key, reduce_val)
        hashed_key = Support.hash(key)
        redis.rpush( Keys.reduce(pid, hashed_key), reduce_val )
      end

      def self.reduced?(pid, key)
        hashed_key = Support.hash(key)
        redis.exists( Keys.reduce(pid, hashed_key) )
      end

      def self.key_collision?(pid, hashed_key, key)
        not ( redis.setnx( Keys.hash_to_key(pid, hashed_key), key ) ||
              redis.get( Keys.hash_to_key(pid, hashed_key) ) == key.to_s )
      end
      
      # Filing a report saves it in the appropriate place, given the info to do so
      #
      # Returns nothing.
      def self.file_report(finalizer, result, pid, keyname)
        rep = finalizer.serialize(result)
        redis.set(Keys.result(pid), rep) if pid
        if keyname
          redis.set(Keys.result_custom_key(keyname), rep) 
          redis.expire(Keys.result_custom_key(keyname), 3600 * 24)
        end
      end

      def self.retrieve_report(keyname)
        redis.get(Keys.result_custom_key(keyname))
      end
      
      def self.shred_report(keyname)
        redis.del(Keys.result_custom_key(keyname))
      end

      # Setup locks on results
      #
      # Examples
      #   Job::Manager::has_lock?(keyname)
      #   # => true or false 
      #
      # Returns true if there's a lock
      def self.has_lock?(keyname)
        "1" == redis.get(lock_key(Keys.result_custom_key(keyname)))
      end
      
      def self.acquire_lock(keyname)
        redis.setnx( lock_key(Keys.result_custom_key(keyname)), 1)
      end
      
      def self.release_lock(keyname)
        redis.del(lock_key(Keys.result_custom_key(keyname)))
      end

      def self.lock_key( key_to_lock )
        "lock.#{key_to_lock}"
      end

      # This will not delete if the master is working
      # It can't get ahold of the files to shred while the master is working
      #
      # Examples
      #   Job::Manager::shred(pid)
      #   # => true or false
      #
      # Returns true as long as the master is not working.
      def self.shred(pid)
        return false if Master.working?(pid)
        redis.keys("map_reduce_job:#{pid}*").each { |k| redis.del(k) }
        redis.srem(Keys.jobs, pid)        
        true
      end

      def self.destroy_all
        redis.smembers(Keys.jobs).each do |pid|
          Job.kill(pid)
        end
        redis.del(Keys.jobs)
      end

      # Find out what map reduce processes are out there
      # 
      # Examples
      #   Job::Manager::get_available_pid
      #
      # Returns an avilable pid.
      def self.get_available_pid
        ( redis.smembers(Keys.jobs).map{|pid| pid.to_i}.max || 0 ) + 1 + rand(20)
      end

      # Find out what map reduce processes are out there
      # 
      # Examples
      #   Job::Manager::ps
      #
      # Returns a list of the map reduce process ids
      def self.ps
        redis.smembers(Keys.jobs)
      end

      # These temp functions are meant to allocate local space
      # for reduce operations to operate on values without having to worry about other workers
      # operating on the same information, i.e. the manager provides support workers (temps)
      # who help do work until it is reclaimed by the manager.
      # 
      # DEPRECATED: No longer in use, because we don't make the assumption that a
      # single reducer does all the work on a single key.
      #
      # Example
      #   Job::Manager::hire_temp(pid, key, agency, name, work)
      #   # => [hashed_key, tempid]
      #
      # Returns an array of the hashed_key and the temp_id.
      def self.hire_temp(pid, key, agency, name, work)
        hashed_key = Support.hash(key)
        temp_id = Keys.temp(pid, hashed_key, agency, name)
        assign_temp( work, Keys.map(pid, hashed_key), temp_id)
        return hashed_key, temp_id
      end

      def self.assign_temp( orig_key, temp_id )
        redis.llen(orig_key).times do 
          redis.rpoplpush( orig_key, temp_id ) 
        end
      end

      def self.get_temp_work(temp_id)
        redis.lrange(temp_id, 0, -1)
      end

      def self.fire_temp(temp_id)
        redis.del(temp_id)
      end
    end
  end
end
